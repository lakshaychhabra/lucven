<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Byte Level Tokenizer | Lucven AI</title>
<meta name="keywords" content="Tokenisation">
<meta name="description" content="Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax)
Hook: Your Hindi users pay 17x more than English users for the same word. Your Arabic users&rsquo; prompts fail because they hit token limits 8x faster. This isn&rsquo;t a bugâ€”it&rsquo;s algorithmic colonialism baked into your tokenizer.

TL;DR: Tokenizers trained on English-heavy data punish non-Latin scripts with massive token inflation. &ldquo;Internationalization&rdquo; = 1 token in English, 17 tokens in Hindi. Your global users are subsidizing your English users, and they&rsquo;re getting worse model performance too.">
<meta name="author" content="Lakshay Chhabra">
<link rel="canonical" href="https://lucven.com/posts/tokenization/byte-level-tokenizer/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lucven.com/favicon_io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lucven.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lucven.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lucven.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://lucven.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lucven.com/posts/tokenization/byte-level-tokenizer/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:url" content="https://lucven.com/posts/tokenization/byte-level-tokenizer/">
  <meta property="og:site_name" content="Lucven AI">
  <meta property="og:title" content="Byte Level Tokenizer">
  <meta property="og:description" content="Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax) Hook: Your Hindi users pay 17x more than English users for the same word. Your Arabic usersâ€™ prompts fail because they hit token limits 8x faster. This isnâ€™t a bugâ€”itâ€™s algorithmic colonialism baked into your tokenizer.
TL;DR: Tokenizers trained on English-heavy data punish non-Latin scripts with massive token inflation. â€œInternationalizationâ€ = 1 token in English, 17 tokens in Hindi. Your global users are subsidizing your English users, and theyâ€™re getting worse model performance too.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-09-02T00:10:39+05:30">
    <meta property="article:modified_time" content="2025-09-02T00:10:39+05:30">
    <meta property="article:tag" content="Tokenisation">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Byte Level Tokenizer">
<meta name="twitter:description" content="Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax)
Hook: Your Hindi users pay 17x more than English users for the same word. Your Arabic users&rsquo; prompts fail because they hit token limits 8x faster. This isn&rsquo;t a bugâ€”it&rsquo;s algorithmic colonialism baked into your tokenizer.

TL;DR: Tokenizers trained on English-heavy data punish non-Latin scripts with massive token inflation. &ldquo;Internationalization&rdquo; = 1 token in English, 17 tokens in Hindi. Your global users are subsidizing your English users, and they&rsquo;re getting worse model performance too.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://lucven.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Byte Level Tokenizer",
      "item": "https://lucven.com/posts/tokenization/byte-level-tokenizer/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Byte Level Tokenizer",
  "name": "Byte Level Tokenizer",
  "description": "Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax) Hook: Your Hindi users pay 17x more than English users for the same word. Your Arabic users\u0026rsquo; prompts fail because they hit token limits 8x faster. This isn\u0026rsquo;t a bugâ€”it\u0026rsquo;s algorithmic colonialism baked into your tokenizer.\nTL;DR: Tokenizers trained on English-heavy data punish non-Latin scripts with massive token inflation. \u0026ldquo;Internationalization\u0026rdquo; = 1 token in English, 17 tokens in Hindi. Your global users are subsidizing your English users, and they\u0026rsquo;re getting worse model performance too.\n",
  "keywords": [
    "Tokenisation"
  ],
  "articleBody": "Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax) Hook: Your Hindi users pay 17x more than English users for the same word. Your Arabic usersâ€™ prompts fail because they hit token limits 8x faster. This isnâ€™t a bugâ€”itâ€™s algorithmic colonialism baked into your tokenizer.\nTL;DR: Tokenizers trained on English-heavy data punish non-Latin scripts with massive token inflation. â€œInternationalizationâ€ = 1 token in English, 17 tokens in Hindi. Your global users are subsidizing your English users, and theyâ€™re getting worse model performance too.\nThe Shocking Reality Check # Same concept, wildly different costs: word = \"internationalization\" English: \"internationalization\" â†’ 1 token ($0.00003) Hindi: \"à¤…à¤‚à¤¤à¤°à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯à¥€à¤•à¤°à¤£\" â†’ 17 tokens ($0.00051) Chinese: \"å›½é™…åŒ–\" â†’ 3 tokens ($0.00009) Arabic: \"ØªØ¯ÙˆÙŠÙ„\" â†’ 4 tokens ($0.00012) Russian: \"Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\" â†’ 8 tokens ($0.00024) # Your Hindi users pay 1,700% more for THE SAME CONCEPT Whatâ€™s Actually Happening Under the Hood Byte-level BPE starts from UTF-8 bytes. Hereâ€™s the brutal math:\n# UTF-8 encoding sizes: \"A\" â†’ 1 byte â†’ likely 1 token \"Ã©\" â†’ 2 bytes â†’ often 1-2 tokens \"ä¸­\" â†’ 3 bytes â†’ usually 2-3 tokens \"ğŸ¤”\" â†’ 4 bytes â†’ often 3-4 tokens \"à¤…\" â†’ 3 bytes â†’ usually 2-3 tokens # But it gets WORSE with frequency bias: \"the\" â†’ Seen millions of times â†’ 1 token \"à¤”à¤°\" â†’ (Hindi \"and\") Seen rarely â†’ 2-3 tokens \"çš„\" â†’ (Chinese \"of\") Common in Chinese data â†’ 1 token \"×©×œ\" â†’ (Hebrew \"of\") Rare in training â†’ 3 tokens The tokenizer literally learns: â€œEnglish patterns deserve compression, others can pay extra.â€\nThe Compound Word Disaster Watch how technical terms explode:\n# English: Efficient compound handling \"machine learning\" â†’ 2 tokens \"artificial intelligence\" â†’ 2 tokens \"blockchain technology\" â†’ 2 tokens # Hindi: Each syllable becomes multiple tokens \"à¤®à¤¶à¥€à¤¨ à¤²à¤°à¥à¤¨à¤¿à¤‚à¤—\" â†’ 8-10 tokens \"à¤•à¥ƒà¤¤à¥à¤°à¤¿à¤® à¤¬à¥à¤¦à¥à¤§à¤¿à¤®à¤¤à¥à¤¤à¤¾\" â†’ 12-15 tokens \"à¤¬à¥à¤²à¥‰à¤•à¤šà¥‡à¤¨ à¤¤à¤•à¤¨à¥€à¤•\" â†’ 10-12 tokens # German (even Latin script suffers!): \"Maschinelles Lernen\" â†’ 4 tokens \"DonaudampfschifffahrtsgesellschaftskapitÃ¤n\" â†’ 15+ tokens # (Danube steamship company captain) The Hidden Performance Penalty Itâ€™s not just about costâ€”non-English users get WORSE models:\n# Effective context window for 4K token limit: English users: 3,000 words of context Hindi users: 500-800 words of context Chinese users: 1,000-1,500 characters Arabic users: 400-600 words of context # Prompt complexity you can handle: English: \"Write a detailed 10-step guide with examples\" â†’ Fits easily Hindi: \"à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ 10-à¤šà¤°à¤£ à¤—à¤¾à¤‡à¤¡ à¤²à¤¿à¤–à¥‡à¤‚\" â†’ Already 30% of budget! Real Production Disasters Disaster 1: The Customer Support Bot Meltdown # English customer: Full conversation history fits messages = [ \"I need help with my order\", \"It was supposed to arrive yesterday\", \"Order number is 12345\", # ... 20 more messages ] # Total: 200 tokens # Arabic customer: Truncated after 5 messages messages = [ \"Ø£Ø­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù…Ø¹ Ø·Ù„Ø¨ÙŠ\", \"ÙƒØ§Ù† Ù…Ù† Ø§Ù„Ù…ÙØªØ±Ø¶ Ø£Ù† ÙŠØµÙ„ Ø£Ù…Ø³\", \"Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨ Ù‡Ùˆ 12345\", # ... only 3 more messages fit ] # Total: 400 tokens (context window hit!) # Result: Arabic customers get \"goldfish memory\" support Disaster 2: The Translation Paradox # You translate your prompts to be inclusive: en_prompt = \"Summarize this document\" # 4 tokens hi_prompt = \"à¤‡à¤¸ à¤¦à¤¸à¥à¤¤à¤¾à¤µà¥‡à¤œà¤¼ à¤•à¤¾ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤¦à¥‡à¤‚\" # 12 tokens # You just 3x'd your costs trying to be inclusive! # Many companies give up and force English-only The Market Reality: Who Gets Screwed? # Token efficiency by language (GPT-4 tokenizer): efficiency_scores = { \"English\": 1.0, # Baseline \"Spanish\": 1.2, # 20% penalty \"French\": 1.15, # 15% penalty \"German\": 1.3, # 30% penalty \"Chinese\": 2.5, # 150% penalty \"Japanese\": 2.2, # 120% penalty \"Hindi\": 3.5, # 250% penalty \"Arabic\": 4.0, # 300% penalty \"Thai\": 4.5, # 350% penalty \"Bengali\": 4.2, # 320% penalty } # If English users pay $100/month: # Bengali users pay $420/month for same usage How to Fix This Injustice Fix 1: The Router Pattern (Use Specialized Models) def smart_model_router(text, detect_language_fn): \"\"\"Route to language-optimized models\"\"\" language = detect_language_fn(text) # Use models with better tokenizers for each language model_map = { 'en': 'gpt-4', # Optimized for English 'zh': 'qwen-plus', # Chinese-optimized tokenizer 'hi': 'llama-3-indic', # Indic language specialist 'ar': 'jais-30b', # Arabic-optimized 'multi': 'aya-23b', # Multilingual balanced } return model_map.get(language, 'aya-23b') # Save 50-70% on non-English queries Fix 2: The Preprocessing Hack (Transliteration) def reduce_hindi_tokens(text): \"\"\"Controversial but effective: Romanize for tokenization\"\"\" # Transliterate to Latin script (Hinglish style) # \"à¤®à¤¶à¥€à¤¨ à¤²à¤°à¥à¤¨à¤¿à¤‚à¤—\" â†’ \"machine learning\" # 8 tokens â†’ 2 tokens (75% reduction!) transliterated = transliterate_to_latin(text) # Process with English-optimized tokenizer response = model.generate(transliterated) # Translate back if needed return transliterate_back(response) # Cuts costs by 60-80% for Indic languages # Trade-off: Loses some nuance Fix 4: The Vocabulary Expansion (If You Control Training) # Add frequent non-English tokens to vocabulary def expand_tokenizer_vocabulary(base_tokenizer, target_languages): \"\"\"Add common words from target languages as single tokens\"\"\" critical_tokens = { 'hi': ['à¤”à¤°', 'à¤•à¥‡', 'à¤¹à¥ˆ', 'à¤®à¥‡à¤‚', 'à¤•à¥€'], # Hindi common words 'ar': ['ÙÙŠ', 'Ù…Ù†', 'Ø¹Ù„Ù‰', 'Ø¥Ù„Ù‰'], # Arabic common words 'zh': ['çš„', 'æ˜¯', 'äº†', 'åœ¨'], # Chinese particles } for lang, tokens in critical_tokens.items(): if lang in target_languages: base_tokenizer.add_tokens(tokens) return base_tokenizer # Reduces token count by 30-40% for target languages Fix 5: The Prompt Caching Strategy class MultilingualPromptCache: \"\"\"Cache tokenized versions of common prompts\"\"\" def __init__(self, tokenizer): self.tokenizer = tokenizer self.cache = {} # Pre-tokenize common prompts in all languages self.common_prompts = { 'summarize': { 'en': \"Summarize this text:\", 'hi': \"à¤‡à¤¸ à¤ªà¤¾à¤  à¤•à¤¾ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤¦à¥‡à¤‚:\", 'zh': \"æ€»ç»“è¿™æ®µæ–‡å­—ï¼š\", 'ar': \"Ù„Ø®Øµ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ:\", } } # Pre-compute token counts for task, translations in self.common_prompts.items(): for lang, prompt in translations.items(): tokens = tokenizer.encode(prompt) self.cache[f\"{task}_{lang}\"] = { 'tokens': tokens, 'count': len(tokens), 'cost': len(tokens) * 0.00003 } def get_cheapest_prompt(self, task): \"\"\"Return the most token-efficient version\"\"\" options = [k for k in self.cache if k.startswith(task)] return min(options, key=lambda x: self.cache[x]['count']) The Benchmark: Test Your Bias def tokenization_bias_test(tokenizer, test_phrase=\"Hello, how are you?\"): \"\"\"Measure your tokenizer's language bias\"\"\" translations = { 'English': \"Hello, how are you?\", 'Spanish': \"Hola, Â¿cÃ³mo estÃ¡s?\", 'Hindi': \"à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?\", 'Chinese': \"ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ\", 'Arabic': \"Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ\", 'Russian': \"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?\", } baseline = len(tokenizer.encode(translations['English'])) print(f\"{'Language':\u003c12} {'Tokens':\u003c8} {'Penalty':\u003c10} {'Extra Cost'}\") print(\"-\" * 45) for lang, text in translations.items(): tokens = len(tokenizer.encode(text)) penalty = (tokens / baseline - 1) * 100 extra_cost = (tokens - baseline) * 0.00003 status = \"âœ…\" if penalty \u003c 50 else \"âš ï¸\" if penalty \u003c 100 else \"ğŸš¨\" print(f\"{lang:\u003c12} {tokens:\u003c8} {penalty:\u003e6.0f}% {status} ${extra_cost:.5f}\") return \"Your tokenizer's bias level\" # Run this test - anything over 100% penalty is problematic The Uncomfortable Truth Most tokenizers are trained on:\n60% English web text 20% Western European languages 10% Chinese (if youâ€™re lucky) 10% â€œOtherâ€ (3 billion people crammed into 10%) This means:\nEnglish speakers get subsidized AI Global South pays the â€œtokenization taxâ€ Models perform worse on non-English tasks True multilingual AI remains expensive ğŸ’¡ Action Item: Calculate your non-English user percentage and their token multiplier. If you have 20% Hindi users paying 3.5x more tokens, youâ€™re leaving money on the table AND providing inferior service. Implement Fix 1 (Router Pattern) this week.\nTakeaway: Tokenization isnâ€™t neutral, itâ€™s a choice about who pays more and whose languages matter. Every English optimized tokenizer is effectively a tax on the Global South. Measure your bias, route intelligently, and stop making your Hindi users subsidize your English ones.\n",
  "wordCount" : "1188",
  "inLanguage": "en",
  "datePublished": "2025-09-02T00:10:39+05:30",
  "dateModified": "2025-09-02T00:10:39+05:30",
  "author":{
    "@type": "Person",
    "name": "Lakshay Chhabra"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lucven.com/posts/tokenization/byte-level-tokenizer/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lucven AI",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lucven.com/favicon_io/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lucven.com/" accesskey="h" title="Lucven AI (Alt + H)">Lucven AI</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lucven.com/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://lucven.com/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://lucven.com/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://lucven.com/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://lucven.com/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://lucven.com/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://lucven.com/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://lucven.com/">Home</a>&nbsp;Â»&nbsp;<a href="https://lucven.com/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Byte Level Tokenizer
    </h1>
    <div class="post-meta"><span title='2025-09-02 00:10:39 +0530 IST'>September 2, 2025</span>&nbsp;Â·&nbsp;6 min&nbsp;Â·&nbsp;Lakshay Chhabra

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#byte-level-tokenizers-can-bloat-non-english-the-colonial-tax" aria-label="Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax)">Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax)</a><ul>
                        
                <li>
                    <a href="#the-shocking-reality-check" aria-label="The Shocking Reality Check">The Shocking Reality Check</a></li>
                <li>
                    <a href="#whats-actually-happening-under-the-hood" aria-label="What&rsquo;s Actually Happening Under the Hood">What&rsquo;s Actually Happening Under the Hood</a></li>
                <li>
                    <a href="#the-compound-word-disaster" aria-label="The Compound Word Disaster">The Compound Word Disaster</a></li>
                <li>
                    <a href="#the-hidden-performance-penalty" aria-label="The Hidden Performance Penalty">The Hidden Performance Penalty</a></li>
                <li>
                    <a href="#real-production-disasters" aria-label="Real Production Disasters">Real Production Disasters</a><ul>
                        
                <li>
                    <a href="#disaster-1-the-customer-support-bot-meltdown" aria-label="Disaster 1: The Customer Support Bot Meltdown">Disaster 1: The Customer Support Bot Meltdown</a></li>
                <li>
                    <a href="#disaster-2-the-translation-paradox" aria-label="Disaster 2: The Translation Paradox">Disaster 2: The Translation Paradox</a></li></ul>
                </li>
                <li>
                    <a href="#the-market-reality-who-gets-screwed" aria-label="The Market Reality: Who Gets Screwed?">The Market Reality: Who Gets Screwed?</a></li>
                <li>
                    <a href="#how-to-fix-this-injustice" aria-label="How to Fix This Injustice">How to Fix This Injustice</a><ul>
                        
                <li>
                    <a href="#fix-1-the-router-pattern-use-specialized-models" aria-label="Fix 1: The Router Pattern (Use Specialized Models)">Fix 1: The Router Pattern (Use Specialized Models)</a></li>
                <li>
                    <a href="#fix-2-the-preprocessing-hack-transliteration" aria-label="Fix 2: The Preprocessing Hack (Transliteration)">Fix 2: The Preprocessing Hack (Transliteration)</a></li>
                <li>
                    <a href="#fix-4-the-vocabulary-expansion-if-you-control-training" aria-label="Fix 4: The Vocabulary Expansion (If You Control Training)">Fix 4: The Vocabulary Expansion (If You Control Training)</a></li>
                <li>
                    <a href="#fix-5-the-prompt-caching-strategy" aria-label="Fix 5: The Prompt Caching Strategy">Fix 5: The Prompt Caching Strategy</a></li></ul>
                </li>
                <li>
                    <a href="#the-benchmark-test-your-bias" aria-label="The Benchmark: Test Your Bias">The Benchmark: Test Your Bias</a></li>
                <li>
                    <a href="#the-uncomfortable-truth" aria-label="The Uncomfortable Truth">The Uncomfortable Truth</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="byte-level-tokenizers-can-bloat-non-english-the-colonial-tax">Byte-Level Tokenizers Can Bloat Non-English (The Colonial Tax)<a hidden class="anchor" aria-hidden="true" href="#byte-level-tokenizers-can-bloat-non-english-the-colonial-tax">#</a></h1>
<p><strong>Hook:</strong> Your Hindi users pay 17x more than English users for the same word. Your Arabic users&rsquo; prompts fail because they hit token limits 8x faster. This isn&rsquo;t a bugâ€”it&rsquo;s algorithmic colonialism baked into your tokenizer.</p>
<blockquote>
<p><strong>TL;DR</strong>: Tokenizers trained on English-heavy data punish non-Latin scripts with massive token inflation. &ldquo;Internationalization&rdquo; = 1 token in English, 17 tokens in Hindi. Your global users are subsidizing your English users, and they&rsquo;re getting worse model performance too.</p></blockquote>
<h2 id="the-shocking-reality-check">The Shocking Reality Check<a hidden class="anchor" aria-hidden="true" href="#the-shocking-reality-check">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Same concept, wildly different costs:</span>
</span></span><span style="display:flex;"><span>word <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;internationalization&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>English:  <span style="color:#e6db74">&#34;internationalization&#34;</span>      <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">1</span> token   (<span style="color:#960050;background-color:#1e0010">$</span><span style="color:#ae81ff">0.00003</span>)
</span></span><span style="display:flex;"><span>Hindi:    <span style="color:#e6db74">&#34;à¤…à¤‚à¤¤à¤°à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯à¥€à¤•à¤°à¤£&#34;</span>           <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">17</span> tokens (<span style="color:#960050;background-color:#1e0010">$</span><span style="color:#ae81ff">0.00051</span>)
</span></span><span style="display:flex;"><span>Chinese:  <span style="color:#e6db74">&#34;å›½é™…åŒ–&#34;</span>                     <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">3</span> tokens  (<span style="color:#960050;background-color:#1e0010">$</span><span style="color:#ae81ff">0.00009</span>)
</span></span><span style="display:flex;"><span>Arabic:   <span style="color:#e6db74">&#34;ØªØ¯ÙˆÙŠÙ„&#34;</span>                      <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">4</span> tokens  (<span style="color:#960050;background-color:#1e0010">$</span><span style="color:#ae81ff">0.00012</span>)
</span></span><span style="display:flex;"><span>Russian:  <span style="color:#e6db74">&#34;Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ&#34;</span>       <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">8</span> tokens  (<span style="color:#960050;background-color:#1e0010">$</span><span style="color:#ae81ff">0.00024</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Your Hindi users pay 1,700% more for THE SAME CONCEPT</span>
</span></span></code></pre></div><h2 id="whats-actually-happening-under-the-hood">What&rsquo;s Actually Happening Under the Hood<a hidden class="anchor" aria-hidden="true" href="#whats-actually-happening-under-the-hood">#</a></h2>
<p>Byte-level BPE starts from UTF-8 bytes. Here&rsquo;s the brutal math:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># UTF-8 encoding sizes:</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;A&#34;</span>     <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">1</span> byte  <span style="color:#960050;background-color:#1e0010">â†’</span> likely <span style="color:#ae81ff">1</span> token
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;Ã©&#34;</span>     <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">2</span> bytes <span style="color:#960050;background-color:#1e0010">â†’</span> often <span style="color:#ae81ff">1</span><span style="color:#f92672">-</span><span style="color:#ae81ff">2</span> tokens  
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;ä¸­&#34;</span>    <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">3</span> bytes <span style="color:#960050;background-color:#1e0010">â†’</span> usually <span style="color:#ae81ff">2</span><span style="color:#f92672">-</span><span style="color:#ae81ff">3</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;ğŸ¤”&#34;</span>    <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">4</span> bytes <span style="color:#960050;background-color:#1e0010">â†’</span> often <span style="color:#ae81ff">3</span><span style="color:#f92672">-</span><span style="color:#ae81ff">4</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;à¤…&#34;</span>     <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">3</span> bytes <span style="color:#960050;background-color:#1e0010">â†’</span> usually <span style="color:#ae81ff">2</span><span style="color:#f92672">-</span><span style="color:#ae81ff">3</span> tokens
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># But it gets WORSE with frequency bias:</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;the&#34;</span>   <span style="color:#960050;background-color:#1e0010">â†’</span> Seen millions of times <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">1</span> token
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;à¤”à¤°&#34;</span>    <span style="color:#960050;background-color:#1e0010">â†’</span> (Hindi <span style="color:#e6db74">&#34;and&#34;</span>) Seen rarely <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">-</span><span style="color:#ae81ff">3</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;çš„&#34;</span>     <span style="color:#960050;background-color:#1e0010">â†’</span> (Chinese <span style="color:#e6db74">&#34;of&#34;</span>) Common <span style="color:#f92672">in</span> Chinese data <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">1</span> token
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;×©×œ&#34;</span>    <span style="color:#960050;background-color:#1e0010">â†’</span> (Hebrew <span style="color:#e6db74">&#34;of&#34;</span>) Rare <span style="color:#f92672">in</span> training <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">3</span> tokens
</span></span></code></pre></div><p>The tokenizer literally learns: &ldquo;English patterns deserve compression, others can pay extra.&rdquo;</p>
<h2 id="the-compound-word-disaster">The Compound Word Disaster<a hidden class="anchor" aria-hidden="true" href="#the-compound-word-disaster">#</a></h2>
<p>Watch how technical terms explode:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># English: Efficient compound handling</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;machine learning&#34;</span>      <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">2</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;artificial intelligence&#34;</span> <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">2</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;blockchain technology&#34;</span> <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">2</span> tokens
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Hindi: Each syllable becomes multiple tokens</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;à¤®à¤¶à¥€à¤¨ à¤²à¤°à¥à¤¨à¤¿à¤‚à¤—&#34;</span>           <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">8</span><span style="color:#f92672">-</span><span style="color:#ae81ff">10</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;à¤•à¥ƒà¤¤à¥à¤°à¤¿à¤® à¤¬à¥à¤¦à¥à¤§à¤¿à¤®à¤¤à¥à¤¤à¤¾&#34;</span>      <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">12</span><span style="color:#f92672">-</span><span style="color:#ae81ff">15</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;à¤¬à¥à¤²à¥‰à¤•à¤šà¥‡à¤¨ à¤¤à¤•à¤¨à¥€à¤•&#34;</span>        <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">10</span><span style="color:#f92672">-</span><span style="color:#ae81ff">12</span> tokens
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># German (even Latin script suffers!):</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;Maschinelles Lernen&#34;</span>  <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">4</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;DonaudampfschifffahrtsgesellschaftskapitÃ¤n&#34;</span> <span style="color:#960050;background-color:#1e0010">â†’</span> <span style="color:#ae81ff">15</span><span style="color:#f92672">+</span> tokens
</span></span><span style="display:flex;"><span><span style="color:#75715e"># (Danube steamship company captain)</span>
</span></span></code></pre></div><h2 id="the-hidden-performance-penalty">The Hidden Performance Penalty<a hidden class="anchor" aria-hidden="true" href="#the-hidden-performance-penalty">#</a></h2>
<p>It&rsquo;s not just about costâ€”non-English users get WORSE models:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Effective context window for 4K token limit:</span>
</span></span><span style="display:flex;"><span>English users:  <span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">000</span> words of context
</span></span><span style="display:flex;"><span>Hindi users:    <span style="color:#ae81ff">500</span><span style="color:#f92672">-</span><span style="color:#ae81ff">800</span> words of context
</span></span><span style="display:flex;"><span>Chinese users:  <span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">000</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">500</span> characters
</span></span><span style="display:flex;"><span>Arabic users:   <span style="color:#ae81ff">400</span><span style="color:#f92672">-</span><span style="color:#ae81ff">600</span> words of context
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Prompt complexity you can handle:</span>
</span></span><span style="display:flex;"><span>English: <span style="color:#e6db74">&#34;Write a detailed 10-step guide with examples&#34;</span>  <span style="color:#960050;background-color:#1e0010">â†’</span> Fits easily
</span></span><span style="display:flex;"><span>Hindi:   <span style="color:#e6db74">&#34;à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ 10-à¤šà¤°à¤£ à¤—à¤¾à¤‡à¤¡ à¤²à¤¿à¤–à¥‡à¤‚&#34;</span>                      <span style="color:#960050;background-color:#1e0010">â†’</span> Already <span style="color:#ae81ff">30</span><span style="color:#f92672">%</span> of budget<span style="color:#960050;background-color:#1e0010">!</span>
</span></span></code></pre></div><h2 id="real-production-disasters">Real Production Disasters<a hidden class="anchor" aria-hidden="true" href="#real-production-disasters">#</a></h2>
<h3 id="disaster-1-the-customer-support-bot-meltdown">Disaster 1: The Customer Support Bot Meltdown<a hidden class="anchor" aria-hidden="true" href="#disaster-1-the-customer-support-bot-meltdown">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># English customer: Full conversation history fits</span>
</span></span><span style="display:flex;"><span>messages <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;I need help with my order&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;It was supposed to arrive yesterday&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Order number is 12345&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ... 20 more messages</span>
</span></span><span style="display:flex;"><span>]  <span style="color:#75715e"># Total: 200 tokens</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Arabic customer: Truncated after 5 messages</span>
</span></span><span style="display:flex;"><span>messages <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Ø£Ø­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù…Ø¹ Ø·Ù„Ø¨ÙŠ&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;ÙƒØ§Ù† Ù…Ù† Ø§Ù„Ù…ÙØªØ±Ø¶ Ø£Ù† ÙŠØµÙ„ Ø£Ù…Ø³&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨ Ù‡Ùˆ 12345&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ... only 3 more messages fit</span>
</span></span><span style="display:flex;"><span>]  <span style="color:#75715e"># Total: 400 tokens (context window hit!)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Result: Arabic customers get &#34;goldfish memory&#34; support</span>
</span></span></code></pre></div><h3 id="disaster-2-the-translation-paradox">Disaster 2: The Translation Paradox<a hidden class="anchor" aria-hidden="true" href="#disaster-2-the-translation-paradox">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># You translate your prompts to be inclusive:</span>
</span></span><span style="display:flex;"><span>en_prompt <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Summarize this document&#34;</span>  <span style="color:#75715e"># 4 tokens</span>
</span></span><span style="display:flex;"><span>hi_prompt <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;à¤‡à¤¸ à¤¦à¤¸à¥à¤¤à¤¾à¤µà¥‡à¤œà¤¼ à¤•à¤¾ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤¦à¥‡à¤‚&#34;</span>  <span style="color:#75715e"># 12 tokens</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># You just 3x&#39;d your costs trying to be inclusive!</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Many companies give up and force English-only</span>
</span></span></code></pre></div><h2 id="the-market-reality-who-gets-screwed">The Market Reality: Who Gets Screwed?<a hidden class="anchor" aria-hidden="true" href="#the-market-reality-who-gets-screwed">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Token efficiency by language (GPT-4 tokenizer):</span>
</span></span><span style="display:flex;"><span>efficiency_scores <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;English&#34;</span>: <span style="color:#ae81ff">1.0</span>,      <span style="color:#75715e"># Baseline</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Spanish&#34;</span>: <span style="color:#ae81ff">1.2</span>,      <span style="color:#75715e"># 20% penalty</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;French&#34;</span>: <span style="color:#ae81ff">1.15</span>,      <span style="color:#75715e"># 15% penalty  </span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;German&#34;</span>: <span style="color:#ae81ff">1.3</span>,       <span style="color:#75715e"># 30% penalty</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Chinese&#34;</span>: <span style="color:#ae81ff">2.5</span>,      <span style="color:#75715e"># 150% penalty</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Japanese&#34;</span>: <span style="color:#ae81ff">2.2</span>,     <span style="color:#75715e"># 120% penalty</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Hindi&#34;</span>: <span style="color:#ae81ff">3.5</span>,        <span style="color:#75715e"># 250% penalty</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Arabic&#34;</span>: <span style="color:#ae81ff">4.0</span>,       <span style="color:#75715e"># 300% penalty</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Thai&#34;</span>: <span style="color:#ae81ff">4.5</span>,         <span style="color:#75715e"># 350% penalty</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Bengali&#34;</span>: <span style="color:#ae81ff">4.2</span>,      <span style="color:#75715e"># 320% penalty</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># If English users pay $100/month:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Bengali users pay $420/month for same usage</span>
</span></span></code></pre></div><h2 id="how-to-fix-this-injustice">How to Fix This Injustice<a hidden class="anchor" aria-hidden="true" href="#how-to-fix-this-injustice">#</a></h2>
<h3 id="fix-1-the-router-pattern-use-specialized-models">Fix 1: The Router Pattern (Use Specialized Models)<a hidden class="anchor" aria-hidden="true" href="#fix-1-the-router-pattern-use-specialized-models">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">smart_model_router</span>(text, detect_language_fn):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Route to language-optimized models&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    language <span style="color:#f92672">=</span> detect_language_fn(text)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Use models with better tokenizers for each language</span>
</span></span><span style="display:flex;"><span>    model_map <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;en&#39;</span>: <span style="color:#e6db74">&#39;gpt-4&#39;</span>,           <span style="color:#75715e"># Optimized for English</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;zh&#39;</span>: <span style="color:#e6db74">&#39;qwen-plus&#39;</span>,       <span style="color:#75715e"># Chinese-optimized tokenizer</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;hi&#39;</span>: <span style="color:#e6db74">&#39;llama-3-indic&#39;</span>,   <span style="color:#75715e"># Indic language specialist</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;ar&#39;</span>: <span style="color:#e6db74">&#39;jais-30b&#39;</span>,        <span style="color:#75715e"># Arabic-optimized</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;multi&#39;</span>: <span style="color:#e6db74">&#39;aya-23b&#39;</span>,      <span style="color:#75715e"># Multilingual balanced</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model_map<span style="color:#f92672">.</span>get(language, <span style="color:#e6db74">&#39;aya-23b&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Save 50-70% on non-English queries</span>
</span></span></code></pre></div><h3 id="fix-2-the-preprocessing-hack-transliteration">Fix 2: The Preprocessing Hack (Transliteration)<a hidden class="anchor" aria-hidden="true" href="#fix-2-the-preprocessing-hack-transliteration">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">reduce_hindi_tokens</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Controversial but effective: Romanize for tokenization&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Transliterate to Latin script (Hinglish style)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># &#34;à¤®à¤¶à¥€à¤¨ à¤²à¤°à¥à¤¨à¤¿à¤‚à¤—&#34; â†’ &#34;machine learning&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 8 tokens â†’ 2 tokens (75% reduction!)</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    transliterated <span style="color:#f92672">=</span> transliterate_to_latin(text)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Process with English-optimized tokenizer</span>
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>generate(transliterated)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Translate back if needed</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> transliterate_back(response)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Cuts costs by 60-80% for Indic languages</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Trade-off: Loses some nuance</span>
</span></span></code></pre></div><h3 id="fix-4-the-vocabulary-expansion-if-you-control-training">Fix 4: The Vocabulary Expansion (If You Control Training)<a hidden class="anchor" aria-hidden="true" href="#fix-4-the-vocabulary-expansion-if-you-control-training">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Add frequent non-English tokens to vocabulary</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">expand_tokenizer_vocabulary</span>(base_tokenizer, target_languages):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Add common words from target languages as single tokens&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    critical_tokens <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;hi&#39;</span>: [<span style="color:#e6db74">&#39;à¤”à¤°&#39;</span>, <span style="color:#e6db74">&#39;à¤•à¥‡&#39;</span>, <span style="color:#e6db74">&#39;à¤¹à¥ˆ&#39;</span>, <span style="color:#e6db74">&#39;à¤®à¥‡à¤‚&#39;</span>, <span style="color:#e6db74">&#39;à¤•à¥€&#39;</span>],  <span style="color:#75715e"># Hindi common words</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;ar&#39;</span>: [<span style="color:#e6db74">&#39;ÙÙŠ&#39;</span>, <span style="color:#e6db74">&#39;Ù…Ù†&#39;</span>, <span style="color:#e6db74">&#39;Ø¹Ù„Ù‰&#39;</span>, <span style="color:#e6db74">&#39;Ø¥Ù„Ù‰&#39;</span>],        <span style="color:#75715e"># Arabic common words</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;zh&#39;</span>: [<span style="color:#e6db74">&#39;çš„&#39;</span>, <span style="color:#e6db74">&#39;æ˜¯&#39;</span>, <span style="color:#e6db74">&#39;äº†&#39;</span>, <span style="color:#e6db74">&#39;åœ¨&#39;</span>],           <span style="color:#75715e"># Chinese particles</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> lang, tokens <span style="color:#f92672">in</span> critical_tokens<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> lang <span style="color:#f92672">in</span> target_languages:
</span></span><span style="display:flex;"><span>            base_tokenizer<span style="color:#f92672">.</span>add_tokens(tokens)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> base_tokenizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Reduces token count by 30-40% for target languages</span>
</span></span></code></pre></div><h3 id="fix-5-the-prompt-caching-strategy">Fix 5: The Prompt Caching Strategy<a hidden class="anchor" aria-hidden="true" href="#fix-5-the-prompt-caching-strategy">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MultilingualPromptCache</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Cache tokenized versions of common prompts&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__init__</span>(self, tokenizer):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tokenizer <span style="color:#f92672">=</span> tokenizer
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>cache <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Pre-tokenize common prompts in all languages</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>common_prompts <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;summarize&#39;</span>: {
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;en&#39;</span>: <span style="color:#e6db74">&#34;Summarize this text:&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;hi&#39;</span>: <span style="color:#e6db74">&#34;à¤‡à¤¸ à¤ªà¤¾à¤  à¤•à¤¾ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤¦à¥‡à¤‚:&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;zh&#39;</span>: <span style="color:#e6db74">&#34;æ€»ç»“è¿™æ®µæ–‡å­—ï¼š&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;ar&#39;</span>: <span style="color:#e6db74">&#34;Ù„Ø®Øµ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ:&#34;</span>,
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Pre-compute token counts</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> task, translations <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>common_prompts<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> lang, prompt <span style="color:#f92672">in</span> translations<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>                tokens <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>encode(prompt)
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>cache[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>task<span style="color:#e6db74">}</span><span style="color:#e6db74">_</span><span style="color:#e6db74">{</span>lang<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;tokens&#39;</span>: tokens,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;count&#39;</span>: len(tokens),
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;cost&#39;</span>: len(tokens) <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.00003</span>
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_cheapest_prompt</span>(self, task):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;Return the most token-efficient version&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        options <span style="color:#f92672">=</span> [k <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>cache <span style="color:#66d9ef">if</span> k<span style="color:#f92672">.</span>startswith(task)]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> min(options, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: self<span style="color:#f92672">.</span>cache[x][<span style="color:#e6db74">&#39;count&#39;</span>])
</span></span></code></pre></div><h2 id="the-benchmark-test-your-bias">The Benchmark: Test Your Bias<a hidden class="anchor" aria-hidden="true" href="#the-benchmark-test-your-bias">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tokenization_bias_test</span>(tokenizer, test_phrase<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Hello, how are you?&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Measure your tokenizer&#39;s language bias&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    translations <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;English&#39;</span>: <span style="color:#e6db74">&#34;Hello, how are you?&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;Spanish&#39;</span>: <span style="color:#e6db74">&#34;Hola, Â¿cÃ³mo estÃ¡s?&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;Hindi&#39;</span>: <span style="color:#e6db74">&#34;à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;Chinese&#39;</span>: <span style="color:#e6db74">&#34;ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;Arabic&#39;</span>: <span style="color:#e6db74">&#34;Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;Russian&#39;</span>: <span style="color:#e6db74">&#34;ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?&#34;</span>,
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    baseline <span style="color:#f92672">=</span> len(tokenizer<span style="color:#f92672">.</span>encode(translations[<span style="color:#e6db74">&#39;English&#39;</span>]))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Language&#39;</span><span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;12</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Tokens&#39;</span><span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;8</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Penalty&#39;</span><span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;10</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Extra Cost&#39;</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;-&#34;</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">45</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> lang, text <span style="color:#f92672">in</span> translations<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>        tokens <span style="color:#f92672">=</span> len(tokenizer<span style="color:#f92672">.</span>encode(text))
</span></span><span style="display:flex;"><span>        penalty <span style="color:#f92672">=</span> (tokens <span style="color:#f92672">/</span> baseline <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>        extra_cost <span style="color:#f92672">=</span> (tokens <span style="color:#f92672">-</span> baseline) <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.00003</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;âœ…&#34;</span> <span style="color:#66d9ef">if</span> penalty <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">50</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;âš ï¸&#34;</span> <span style="color:#66d9ef">if</span> penalty <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">100</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;ğŸš¨&#34;</span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>lang<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;12</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>tokens<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;8</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>penalty<span style="color:#e6db74">:</span><span style="color:#e6db74">&gt;6.0f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">% </span><span style="color:#e6db74">{</span>status<span style="color:#e6db74">}</span><span style="color:#e6db74">  $</span><span style="color:#e6db74">{</span>extra_cost<span style="color:#e6db74">:</span><span style="color:#e6db74">.5f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;Your tokenizer&#39;s bias level&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run this test - anything over 100% penalty is problematic</span>
</span></span></code></pre></div><h2 id="the-uncomfortable-truth">The Uncomfortable Truth<a hidden class="anchor" aria-hidden="true" href="#the-uncomfortable-truth">#</a></h2>
<p><strong>Most tokenizers are trained on:</strong></p>
<ul>
<li>60% English web text</li>
<li>20% Western European languages</li>
<li>10% Chinese (if you&rsquo;re lucky)</li>
<li>10% &ldquo;Other&rdquo; (3 billion people crammed into 10%)</li>
</ul>
<p><strong>This means:</strong></p>
<ul>
<li>English speakers get subsidized AI</li>
<li>Global South pays the &ldquo;tokenization tax&rdquo;</li>
<li>Models perform worse on non-English tasks</li>
<li>True multilingual AI remains expensive</li>
</ul>
<hr>
<blockquote>
<p><strong>ğŸ’¡ Action Item</strong>: Calculate your non-English user percentage and their token multiplier. If you have 20% Hindi users paying 3.5x more tokens, you&rsquo;re leaving money on the table AND providing inferior service. Implement Fix 1 (Router Pattern) this week.</p></blockquote>
<hr>
<p><strong>Takeaway:</strong> Tokenization isn&rsquo;t neutral, it&rsquo;s a choice about who pays more and whose languages matter. Every English optimized tokenizer is effectively a tax on the Global South. Measure your bias, route intelligently, and stop making your Hindi users subsidize your English ones.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lucven.com/tags/tokenisation/">Tokenisation</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://lucven.com/posts/tokenization/forensics/">
    <span class="title">Â« Prev</span>
    <br>
    <span>Tokenization Forensics about Leaks</span>
  </a>
  <a class="next" href="https://lucven.com/posts/tokenization/tokenization/">
    <span class="title">Next Â»</span>
    <br>
    <span>Tokenisation: Why 90% of LLM Failures Start Here</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Byte Level Tokenizer on x"
            href="https://x.com/intent/tweet/?text=Byte%20Level%20Tokenizer&amp;url=https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f&amp;hashtags=Tokenisation">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Byte Level Tokenizer on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f&amp;title=Byte%20Level%20Tokenizer&amp;summary=Byte%20Level%20Tokenizer&amp;source=https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Byte Level Tokenizer on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f&title=Byte%20Level%20Tokenizer">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Byte Level Tokenizer on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Byte Level Tokenizer on whatsapp"
            href="https://api.whatsapp.com/send?text=Byte%20Level%20Tokenizer%20-%20https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Byte Level Tokenizer on telegram"
            href="https://telegram.me/share/url?text=Byte%20Level%20Tokenizer&amp;url=https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Byte Level Tokenizer on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Byte%20Level%20Tokenizer&u=https%3a%2f%2flucven.com%2fposts%2ftokenization%2fbyte-level-tokenizer%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer><script src="https://giscus.app/client.js"
  data-repo="lakshaychhabra/lucven-comments"
  data-repo-id="R_kgDOPYOEYw"
  data-category="Q&A"
  data-category-id="DIC_kwDOPYOEY84CtxWt"
  data-mapping="pathname"
  data-strict="0"
  data-reactions-enabled="1"
  data-emit-metadata="0"
  data-input-position="top"
  data-theme="preferred_color_scheme"
  data-lang="en"
  data-loading="lazy"
  crossorigin="anonymous"
  async>
</script>


</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lucven.com/">Lucven AI</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
